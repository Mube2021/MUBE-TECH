{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpbpqdZP8HxQqrglqeIG6r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mube2021/MUBE-TECH/blob/main/allin_one.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TR_PRisxitYw"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "import torch\n",
        "import time\n",
        "\n",
        "from sqlalchemy import create_engine\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from summarizer import Summarizer\n",
        "\n",
        "\n",
        "# functions for generating summary\n",
        "\n",
        "def ext_sum(text, ratio=0.8):\n",
        "    \"\"\"\n",
        "    Generate extractive summary using BERT model\n",
        "\n",
        "    INPUT:\n",
        "    text - str. Input text\n",
        "    ratio - float. Enter a ratio between 0.1 - 1.0 [default = 0.8]\n",
        "            (ratio = summary length / original text length)\n",
        "\n",
        "    OUTPUT:\n",
        "    summary - str. Generated summary\n",
        "    \"\"\"\n",
        "    bert_model = Summarizer()\n",
        "    summary = bert_model(text, ratio=ratio)\n",
        "\n",
        "    return summary\n",
        "\n",
        "def abs_sum(text, model, tokenizer, min_length=80,\n",
        "                     max_length=150, length_penalty=15,\n",
        "                     num_beams=2):\n",
        "    \"\"\"\n",
        "    Generate abstractive summary using T5 model\n",
        "\n",
        "    INPUT:\n",
        "    text - str. Input text\n",
        "    model - model name\n",
        "    tokenizer - model tokenizer\n",
        "    min_length - int. The min length of the sequence to be generated\n",
        "                      [default = 80]\n",
        "    max_length - int. The max length of the sequence to be generated\n",
        "                      [default = 150]\n",
        "    length_penalty - float. Set to values < 1.0 in order to encourage the model\n",
        "                     to generate shorter sequences, to a value > 1.0 in order to\n",
        "                     encourage the model to produce longer sequences.\n",
        "                     [default = 15]\n",
        "    num_beams - int. Number of beams for beam search. 1 means no beam search\n",
        "                     [default = 2]\n",
        "\n",
        "    OUTPUT:\n",
        "    summary - str. Generated summary\n",
        "    \"\"\"\n",
        "    tokens_input = tokenizer.encode(\"summarize: \"+text, return_tensors='pt',\n",
        "                                    # model tokens max input length\n",
        "                                    max_length=tokenizer.model_max_length,\n",
        "                                    truncation=True)\n",
        "\n",
        "    summary_ids = model.generate(tokens_input,\n",
        "                                min_length=min_length,\n",
        "                                max_length=max_length,\n",
        "                                length_penalty=length_penalty,\n",
        "                                num_beams=num_beams)\n",
        "\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return summary\n",
        "\n",
        "def generate_summary(text, model, tokenizer, ext_ratio=1.0, min_length=80,\n",
        "                     max_length=150, length_penalty=15,\n",
        "                     num_beams=2):\n",
        "    \"\"\"\n",
        "    Generate summary for using extractive & abstractive methods\n",
        "\n",
        "    INPUT:\n",
        "    text - str. Input text\n",
        "    model - model name\n",
        "    tokenizer - model tokenizer\n",
        "    ext_ratio - float. Enter a ratio between 0.1 - 1.0 [default = 1.0]\n",
        "                (ratio = summary length / original text length)\n",
        "                1.0 means no extractive summarization is performed before\n",
        "                abstractive summarization\n",
        "    min_length - int. The min length of the sequence to be generated\n",
        "                 [default = 80]\n",
        "    max_length - int. The max length of the sequence to be generated\n",
        "                 [default = 150]\n",
        "    length_penalty - float. Set to values < 1.0 in order to encourage the model\n",
        "                     to generate shorter sequences, to a value > 1.0 in order to\n",
        "                     encourage the model to produce longer sequences.\n",
        "                     [default = 15]\n",
        "    num_beams - int. Number of beams for beam search. 1 means no beam search\n",
        "                     [default = 2]\n",
        "\n",
        "    OUTPUT:\n",
        "    summary - str. Generated summary\n",
        "    \"\"\"\n",
        "    if ext_ratio == 1.0:\n",
        "        summary = abs_sum(text, model, tokenizer, min_length,\n",
        "                       max_length, length_penalty, num_beams)\n",
        "    elif ext_ratio < 1.0:\n",
        "        text = ext_sum(text, ratio = ext_ratio)\n",
        "        summary = abs_sum(text, model, tokenizer, min_length,\n",
        "                       max_length, length_penalty, num_beams)\n",
        "    else:\n",
        "        print('Error! Please enter ext_ratio betwen 0.1 and 1.0')\n",
        "\n",
        "    return summary\n",
        "\n",
        "# function to generate summary and save output to list and text file\n",
        "# please be patience, as this loop will take some time to run\n",
        "def gen_sum_save_monitor(df, model, tokenizer, output_folder, ext_ratio=1.0,\n",
        "                         min_length=80, max_length=150, length_penalty=15,\n",
        "                         num_beams=2):\n",
        "    \"\"\"\n",
        "    Monitor progress while generating summary & save output to list & text file\n",
        "\n",
        "    INPUT:\n",
        "    df - DataFrama. Data loaded from database\n",
        "    model - model name\n",
        "    tokenizer - model tokenizer\n",
        "    output_folder - str. Folder name to save the generated output in text file\n",
        "    ext_ratio - float. Enter a ratio between 0.1 - 1.0 [default = 1.0]\n",
        "                (ratio = summary length / original text length)\n",
        "                1.0 means no extractive summarization is performed before\n",
        "                abstractive summarization\n",
        "    min_length - int. The min length of the sequence to be generated\n",
        "                 [default = 80]\n",
        "    max_length - int. The max length of the sequence to be generated\n",
        "                 [default = 150]\n",
        "    length_penalty - float. Set to values < 1.0 in order to encourage the model\n",
        "                     to generate shorter sequences, to a value > 1.0 in order to\n",
        "                     encourage the model to produce longer sequences.\n",
        "                     [default = 15]\n",
        "    num_beams - int. Number of beams for beam search. 1 means no beam search\n",
        "                [default = 2]\n",
        "\n",
        "    OUTPUT:\n",
        "    summaries - list. Generated summary appended to a list\n",
        "    \"\"\"\n",
        "    # create an empty list\n",
        "    summaries = []\n",
        "    # loop through each raw_text row in dataset, generate summary,\n",
        "    # append summary to summaries list\n",
        "    for i in range(len(df)):\n",
        "        file_path = df.file_path[i]\n",
        "        raw_text = df.raw_text[i]\n",
        "\n",
        "        start = time.time()\n",
        "        summary = generate_summary(raw_text, model, tokenizer,\n",
        "                                   ext_ratio, min_length, max_length,\n",
        "                                   length_penalty, num_beams)\n",
        "\n",
        "        file_name = file_path[8:][:-4]+'_summary.txt'\n",
        "\n",
        "        with open(output_folder + \"/\" + file_name, 'w')as text_file:\n",
        "            text_file.write(summary)\n",
        "\n",
        "\n",
        "        summaries.append(summary)\n",
        "        end = time.time()\n",
        "        print(\" Summarized '{}'[time: {:.2f}s]\".format(file_path,\n",
        "                                                       end-start))\n",
        "\n",
        "    return summaries\n",
        "\n",
        "def main():\n",
        "    if len(sys.argv) == 8:\n",
        "        database_filepath, model_name, output_folder, ext_ratio, min_length, \\\n",
        "        max_length, length_penalty = sys.argv[1:]\n",
        "\n",
        "        print('\\nLoading data...\\n DATABASE: {}'.format(database_filepath))\n",
        "        engine = create_engine('sqlite:///'+database_filepath)\n",
        "        df = pd.read_sql_table('Text_table', engine)\n",
        "\n",
        "        print('\\nLoading pre-train model and tokenizer...'\\\n",
        "              '\\n MODEL : {}'.format(model_name))\n",
        "        model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "        print(' {} model has been loaded'.format(model_name))\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        print(' {} tokenizer has been loaded'.format(model_name))\n",
        "\n",
        "        print('\\nGenerating summary...')\n",
        "        print('Please be patience, this will take some time to run')\n",
        "        summaries = gen_sum_save_monitor(df, model, tokenizer, output_folder,\n",
        "                                    float(ext_ratio), int(min_length),\n",
        "                                    int(max_length), float(length_penalty))\n",
        "\n",
        "        # create a new 'summary' column and append to df\n",
        "        df['summary'] = summaries\n",
        "\n",
        "        print('\\nSaving summary...\\n DATABASE: {}'.format(database_filepath))\n",
        "        engine = create_engine('sqlite:///'+database_filepath)\n",
        "        df.to_sql('Text_table', engine, if_exists = 'replace', index=False)\n",
        "\n",
        "        print('\\nSummary saved to database')\n",
        "    else:\n",
        "        print('Please provide: '\\\n",
        "            '\\n 1) first argument: filepath to text database'\\\n",
        "            '\\n 2) second argument: model name'\\\n",
        "            '\\n 3) third argument: filepath to output folder'\\\n",
        "            '\\n 4) forth argument: ext_ratio'\\\n",
        "            '\\n 5) fifth argument: min_length'\\\n",
        "            '\\n 6) sixth argument: max_length'\\\n",
        "            '\\n 7) seventh argument: length_penalty'\n",
        "            ' \\n\\n Example: python models/summarization.py data/Text.db t5-base '\\\n",
        "            'data/output 1.0 80 150 15')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ]
}